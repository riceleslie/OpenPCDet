self.anchors_size 3
batch_dict dict_keys(['points', 'frame_id', 'gt_boxes', 'use_lead_xyz', 'voxels', 'voxel_coords', 'voxel_num_points', 'image_shape', 'batch_size'])

----------------MeanVFE-------------------
batch_dict: dict_keys(['points', 'frame_id', 'gt_boxes', 'use_lead_xyz', 'voxels', 'voxel_coords', 'voxel_num_points', 'image_shape', 'batch_size', 'voxel_features'])
------------------------------------------

-----------------------VoxelBackBone----------------------------
data_dict: dict_keys(['points', 'frame_id', 'gt_boxes', 'use_lead_xyz', 'voxels', 'voxel_coords', 'voxel_num_points', 'image_shape', 'batch_size', 'voxel_features', 'encoded_spconv_tensor', 'encoded_spconv_tensor_stride', 'multi_scale_3d_features'])
---------------------------------------------------------------

---------------------------HeightCompression-----------------------
batch_dict: dict_keys(['points', 'frame_id', 'gt_boxes', 'use_lead_xyz', 'voxels', 'voxel_coords', 'voxel_num_points', 'image_shape', 'batch_size', 'voxel_features', 'encoded_spconv_tensor', 'encoded_spconv_tensor_stride', 'multi_scale_3d_features', 'spatial_features', 'spatial_features_stride'])
-------------------------------------------------------------------

------------------------BEVBackBone--------------------------------
spatial_features_size:  torch.Size([1, 256, 200, 176]) 

data_dict:  dict_keys(['points', 'frame_id', 'gt_boxes', 'use_lead_xyz', 'voxels', 'voxel_coords', 'voxel_num_points', 'image_shape', 'batch_size', 'voxel_features', 'encoded_spconv_tensor', 'encoded_spconv_tensor_stride', 'multi_scale_3d_features', 'spatial_features', 'spatial_features_stride', 'spatial_features_2d']) 

spatial_features_2d_size:  torch.Size([1, 512, 200, 176]) 

-------------------------------------------------------------------

------------------------------AnchorHead--------------------------
cls_preds_size:  torch.Size([1, 18, 200, 176]) 

box_preds_size:  torch.Size([1, 42, 200, 176]) 


########## assign taget
gt_boxes_with_classes_shape:  torch.Size([1, 29, 8]) 

gt_classes_shape:  torch.Size([1, 29]) 

gt_boxes_shape:  torch.Size([1, 29, 7]) 

cur_gt_shape:  torch.Size([29, 7]) 

cnt:  28 

cur_gt_classes_shape:  torch.Size([29]) 

anchor_class_name:  Car
anchors:  torch.Size([1, 200, 176, 1, 2, 7]) 

mask:  tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False],
       dtype=torch.bool) 

selected_classes:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.int32) 

anchor_by_gt_overlap:  torch.Size([70400, 10]) 

anchor_class_name:  Pedestrian
anchors:  torch.Size([1, 200, 176, 1, 2, 7]) 

mask:  tensor([False, False, False, False, False, False, False, False, False, False,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True, False, False, False, False, False],
       dtype=torch.bool) 

selected_classes:  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0',
       dtype=torch.int32) 

anchor_by_gt_overlap:  torch.Size([70400, 14]) 

anchor_class_name:  Cyclist
anchors:  torch.Size([1, 200, 176, 1, 2, 7]) 

mask:  tensor([False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False,  True,  True,  True,  True,  True],
       dtype=torch.bool) 

selected_classes:  tensor([3, 3, 3, 3, 3], device='cuda:0', dtype=torch.int32) 

anchor_by_gt_overlap:  torch.Size([70400, 5]) 

data_dict:  dict_keys(['points', 'frame_id', 'gt_boxes', 'use_lead_xyz', 'voxels', 'voxel_coords', 'voxel_num_points', 'image_shape', 'batch_size', 'voxel_features', 'encoded_spconv_tensor', 'encoded_spconv_tensor_stride', 'multi_scale_3d_features', 'spatial_features', 'spatial_features_stride', 'spatial_features_2d']) 

-------------------------------------------------------------------


########## get_cls_layer_loss ##########

cls_weights_1:  torch.Size([1, 211200]) 

cls_weights_2:  torch.Size([1, 211200]) 

one_hot_targets_3:  torch.Size([1, 211200, 3]) 


########## get_box_reg_layer_loss ##########

reg_weights_1:  torch.Size([1, 211200]) 

reg_weights_2:  torch.Size([1, 211200]) 

